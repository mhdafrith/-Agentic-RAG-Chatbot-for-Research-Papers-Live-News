{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36cfafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59789/546661828.py:31: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Lost in Translation: Large Language Models in Non-English Content Analysis\n",
      "Extracting text from arxiv_papers/2306.07377v1.pdf\n",
      "Downloading Cedille: A large autoregressive French language model\n",
      "Extracting text from arxiv_papers/2202.03371v1.pdf\n",
      "Downloading How Good are Commercial Large Language Models on African Languages?\n",
      "Extracting text from arxiv_papers/2305.06530v1.pdf\n",
      "Downloading Goldfish: Monolingual Language Models for 350 Languages\n",
      "Extracting text from arxiv_papers/2408.10441v1.pdf\n",
      "Downloading Modelling Language\n",
      "Extracting text from arxiv_papers/2404.09579v1.pdf\n",
      "Downloading LLaMA-Reg: Using LLaMA 2 for Unsupervised Medical Image Registration\n",
      "Extracting text from arxiv_papers/2405.18774v1.pdf\n",
      "Downloading A Precis of Language Models are not Models of Language\n",
      "Extracting text from arxiv_papers/2205.07634v1.pdf\n",
      "Downloading A Survey of Large Language Models for European Languages\n",
      "Extracting text from arxiv_papers/2408.15040v2.pdf\n",
      "Downloading Beyond the limitations of any imaginable mechanism: large language models and psycholinguistics\n",
      "Extracting text from arxiv_papers/2303.00077v1.pdf\n",
      "Downloading Enhance Reasoning Ability of Visual-Language Models via Large Language Models\n",
      "Extracting text from arxiv_papers/2305.13267v1.pdf\n",
      "Downloading Should we Stop Training More Monolingual Models, and Simply Use Machine Translation Instead?\n",
      "Extracting text from arxiv_papers/2104.10441v1.pdf\n",
      "Downloading Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks\n",
      "Extracting text from arxiv_papers/2305.13782v1.pdf\n",
      "Downloading The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models\n",
      "Extracting text from arxiv_papers/2501.09653v1.pdf\n",
      "Downloading Formal Aspects of Language Modeling\n",
      "Extracting text from arxiv_papers/2311.04329v2.pdf\n",
      "Downloading When Being Unseen from mBERT is just the Beginning: Handling New Languages With Multilingual Language Models\n",
      "Extracting text from arxiv_papers/2010.12858v2.pdf\n",
      "Downloading Evaluation Methodology for Large Language Models for Multilingual Document Question and Answer\n",
      "Extracting text from arxiv_papers/2402.01065v1.pdf\n",
      "Downloading Multilingual MFA: Forced Alignment on Low-Resource Related Languages\n",
      "Extracting text from arxiv_papers/2504.07315v2.pdf\n",
      "Downloading Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind\n",
      "Extracting text from arxiv_papers/2404.04748v2.pdf\n",
      "Downloading BELL: Benchmarking the Explainability of Large Language Models\n",
      "Extracting text from arxiv_papers/2504.18572v1.pdf\n",
      "Downloading Improving Arithmetic Reasoning Ability of Large Language Models through Relation Tuples, Verification and Dynamic Feedback\n",
      "Extracting text from arxiv_papers/2406.17873v1.pdf\n",
      "Downloading Large Language Models are not Models of Natural Language: they are Corpus Models\n",
      "Extracting text from arxiv_papers/2112.07055v2.pdf\n",
      "Downloading Dynamic Fusion: Attentional Language Model for Neural Machine Translation\n",
      "Extracting text from arxiv_papers/1909.04879v1.pdf\n",
      "Downloading BigTranslate: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages\n",
      "Extracting text from arxiv_papers/2305.18098v3.pdf\n",
      "Downloading Lugha-Llama: Adapting Large Language Models for African Languages\n",
      "Extracting text from arxiv_papers/2504.06536v1.pdf\n",
      "Downloading Can Large Language Models design a Robot?\n",
      "Extracting text from arxiv_papers/2303.15324v1.pdf\n",
      "Downloading Investigating Language-Specific Calibration For Pruning Multilingual Large Language Models\n",
      "Extracting text from arxiv_papers/2408.14398v3.pdf\n",
      "Downloading Still \"Talking About Large Language Models\": Some Clarifications\n",
      "Extracting text from arxiv_papers/2412.10291v1.pdf\n",
      "Downloading Scientific Computing with Large Language Models\n",
      "Extracting text from arxiv_papers/2406.07259v1.pdf\n",
      "Downloading PersianLLaMA: Towards Building First Persian Large Language Model\n",
      "Extracting text from arxiv_papers/2312.15713v1.pdf\n",
      "Downloading Assessing Translation capabilities of Large Language Models involving English and Indian Languages\n",
      "Extracting text from arxiv_papers/2311.09216v1.pdf\n",
      "Downloading Exploring Multilingual Probing in Large Language Models: A Cross-Language Analysis\n",
      "Extracting text from arxiv_papers/2409.14459v2.pdf\n",
      "Downloading Unsupervised Improvement of Factual Knowledge in Language Models\n",
      "Extracting text from arxiv_papers/2304.01597v1.pdf\n",
      "Downloading Model Compression and Efficient Inference for Large Language Models: A Survey\n",
      "Extracting text from arxiv_papers/2402.09748v1.pdf\n",
      "Downloading Gl√≥rIA -- A Generative and Open Large Language Model for Portuguese\n",
      "Extracting text from arxiv_papers/2402.12969v1.pdf\n",
      "Downloading Jigsaw: Large Language Models meet Program Synthesis\n",
      "Extracting text from arxiv_papers/2112.02969v1.pdf\n",
      "Downloading Large Language Models for Judicial Entity Extraction: A Comparative Study\n",
      "Extracting text from arxiv_papers/2407.05786v1.pdf\n",
      "Downloading Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model\n",
      "Extracting text from arxiv_papers/2312.01090v2.pdf\n",
      "Downloading TigerLLM - A Family of Bangla Large Language Models\n",
      "Extracting text from arxiv_papers/2503.10995v2.pdf\n",
      "Downloading The Sociolinguistic Foundations of Language Modeling\n",
      "Extracting text from arxiv_papers/2407.09241v1.pdf\n",
      "Downloading Dynamic data sampler for cross-language transfer learning in large language models\n",
      "Extracting text from arxiv_papers/2405.10626v1.pdf\n",
      "Downloading UIO at SemEval-2023 Task 12: Multilingual fine-tuning for sentiment classification in low-resource languages\n",
      "Extracting text from arxiv_papers/2304.14189v1.pdf\n",
      "Downloading Exploring Cross-lingual Textual Style Transfer with Large Multilingual Language Models\n",
      "Extracting text from arxiv_papers/2206.02252v1.pdf\n",
      "Downloading Multilingual Text Classification for Dravidian Languages\n",
      "Extracting text from arxiv_papers/2112.01705v1.pdf\n",
      "Downloading Dynamic Large Language Models on Blockchains\n",
      "Extracting text from arxiv_papers/2307.10549v1.pdf\n",
      "Downloading MoE-CT: A Novel Approach For Large Language Models Training With Resistance To Catastrophic Forgetting\n",
      "Extracting text from arxiv_papers/2407.00875v1.pdf\n",
      "Downloading An Efficient Approach for Studying Cross-Lingual Transfer in Multilingual Language Models\n",
      "Extracting text from arxiv_papers/2403.20088v1.pdf\n",
      "Downloading BQA: Body Language Question Answering Dataset for Video Large Language Models\n",
      "Extracting text from arxiv_papers/2410.13206v2.pdf\n",
      "Downloading Larger-Scale Transformers for Multilingual Masked Language Modeling\n",
      "Extracting text from arxiv_papers/2105.00572v1.pdf\n",
      "Downloading Teach me with a Whisper: Enhancing Large Language Models for Analyzing Spoken Transcripts using Speech Embeddings\n",
      "Extracting text from arxiv_papers/2311.07014v1.pdf\n",
      "Downloading What Drives Performance in Multilingual Language Models?\n",
      "Extracting text from arxiv_papers/2404.19159v1.pdf\n",
      "Downloading Planning with Logical Graph-based Language Model for Instruction Generation\n",
      "Extracting text from arxiv_papers/2308.13782v2.pdf\n",
      "Downloading Reimagining Retrieval Augmented Language Models for Answering Queries\n",
      "Extracting text from arxiv_papers/2306.01061v1.pdf\n",
      "Downloading HinFlair: pre-trained contextual string embeddings for pos tagging and text classification in the Hindi language\n",
      "Extracting text from arxiv_papers/2101.06949v1.pdf\n",
      "Downloading How Many Languages Make Good Multilingual Instruction Tuning? A Case Study on BLOOM\n",
      "Extracting text from arxiv_papers/2404.04850v2.pdf\n",
      "Downloading From N-grams to Pre-trained Multilingual Models For Language Identification\n",
      "Extracting text from arxiv_papers/2410.08728v1.pdf\n",
      "Downloading An Assessment on Comprehending Mental Health through Large Language Models\n",
      "Extracting text from arxiv_papers/2401.04592v2.pdf\n",
      "Downloading Can Large Language Model Comprehend Ancient Chinese? A Preliminary Test on ACLUE\n",
      "Extracting text from arxiv_papers/2310.09550v1.pdf\n",
      "Downloading Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models\n",
      "Extracting text from arxiv_papers/2311.09194v1.pdf\n",
      "Downloading GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding\n",
      "Extracting text from arxiv_papers/2311.09707v1.pdf\n",
      "Downloading Towards Automatic Support of Software Model Evolution with Large Language~Models\n",
      "Extracting text from arxiv_papers/2312.12404v1.pdf\n",
      "Downloading Watermarking LLMs with Weight Quantization\n",
      "Extracting text from arxiv_papers/2310.11237v1.pdf\n",
      "Downloading An Overview and Discussion on Using Large Language Models for Implementation Generation of Solutions to Open-Ended Problems\n",
      "Extracting text from arxiv_papers/2501.00562v2.pdf\n",
      "Downloading Language Models reach higher Agreement than Humans in Historical Interpretation\n",
      "Extracting text from arxiv_papers/2504.02572v1.pdf\n",
      "Downloading Theory of Hallucinations based on Equivariance\n",
      "Extracting text from arxiv_papers/2312.14504v2.pdf\n",
      "Downloading A Transformer with Stack Attention\n",
      "Extracting text from arxiv_papers/2405.04515v2.pdf\n",
      "Downloading Low-Resource Language Modelling of South African Languages\n",
      "Extracting text from arxiv_papers/2104.00772v1.pdf\n",
      "Downloading In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages\n",
      "Extracting text from arxiv_papers/2302.12299v1.pdf\n",
      "Downloading Hire a Linguist!: Learning Endangered Languages with In-Context Linguistic Descriptions\n",
      "Extracting text from arxiv_papers/2402.18025v2.pdf\n",
      "Downloading MaLLaM -- Malaysia Large Language Model\n",
      "Extracting text from arxiv_papers/2401.14680v2.pdf\n",
      "Downloading AI for Biomedicine in the Era of Large Language Models\n",
      "Extracting text from arxiv_papers/2403.15673v1.pdf\n",
      "Downloading TabLLM: Few-shot Classification of Tabular Data with Large Language Models\n",
      "Extracting text from arxiv_papers/2210.10723v2.pdf\n",
      "Downloading Can Character-based Language Models Improve Downstream Task Performance in Low-Resource and Noisy Language Scenarios?\n",
      "Extracting text from arxiv_papers/2110.13658v1.pdf\n",
      "Downloading The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units\n",
      "Extracting text from arxiv_papers/2411.02280v2.pdf\n",
      "Downloading Learning Translation Quality Evaluation on Low Resource Languages from Large Language Models\n",
      "Extracting text from arxiv_papers/2302.03491v1.pdf\n",
      "Downloading Investigating the Translation Performance of a Large Multilingual Language Model: the Case of BLOOM\n",
      "Extracting text from arxiv_papers/2303.01911v2.pdf\n",
      "Downloading Visual Conceptual Blending with Large-scale Language and Vision Models\n",
      "Extracting text from arxiv_papers/2106.14127v1.pdf\n",
      "Downloading Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training\n",
      "Extracting text from arxiv_papers/2403.15470v1.pdf\n",
      "Downloading Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning\n",
      "Extracting text from arxiv_papers/2410.16843v1.pdf\n",
      "Downloading LLaMA-Gene: A General-purpose Gene Task Large Language Model Based on Instruction Fine-tuning\n",
      "Extracting text from arxiv_papers/2412.00471v1.pdf\n",
      "Downloading Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks\n",
      "Extracting text from arxiv_papers/2501.06286v1.pdf\n",
      "Downloading Standard Language Ideology in AI-Generated Language\n",
      "Extracting text from arxiv_papers/2406.08726v1.pdf\n",
      "Downloading Pruning Multilingual Large Language Models for Multilingual Inference\n",
      "Extracting text from arxiv_papers/2409.16911v2.pdf\n",
      "Downloading Benchmarking Language Models for Code Syntax Understanding\n",
      "Extracting text from arxiv_papers/2210.14473v1.pdf\n",
      "Downloading Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning\n",
      "Extracting text from arxiv_papers/2412.15797v1.pdf\n",
      "Downloading MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing\n",
      "Extracting text from arxiv_papers/2408.11396v1.pdf\n",
      "Downloading CoCo-CoLa: Evaluating Language Adherence in Multilingual LLMs\n",
      "Extracting text from arxiv_papers/2502.12476v1.pdf\n",
      "Downloading Zero Resource Cross-Lingual Part Of Speech Tagging\n",
      "Extracting text from arxiv_papers/2401.05727v1.pdf\n",
      "Downloading Learning Transfers over Several Programming Languages\n",
      "Extracting text from arxiv_papers/2310.16937v2.pdf\n",
      "Downloading Large Language Models are Biased Because They Are Large Language Models\n",
      "Extracting text from arxiv_papers/2406.13138v2.pdf\n",
      "Downloading Garbage in, garbage out: Zero-shot detection of crime using Large Language Models\n",
      "Extracting text from arxiv_papers/2307.06844v1.pdf\n",
      "Downloading Towards Harnessing Large Language Models for Comprehension of Conversational Grounding\n",
      "Extracting text from arxiv_papers/2406.01749v1.pdf\n",
      "Downloading Evaluating the Translation Performance of Large Language Models Based on Euas-20\n",
      "Extracting text from arxiv_papers/2408.03119v1.pdf\n",
      "Downloading LLaSM: Large Language and Speech Model\n",
      "Extracting text from arxiv_papers/2308.15930v3.pdf\n",
      "Downloading Investigating Robustness of Dialog Models to Popular Figurative Language Constructs\n",
      "Extracting text from arxiv_papers/2110.00687v1.pdf\n",
      "Downloading DPRK-BERT: The Supreme Language Model\n",
      "Extracting text from arxiv_papers/2112.00567v1.pdf\n",
      "Downloading Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills\n",
      "Extracting text from arxiv_papers/2308.15118v1.pdf\n",
      "Downloading LLaMo: Large Language Model-based Molecular Graph Assistant\n",
      "Extracting text from arxiv_papers/2411.00871v1.pdf\n",
      "Downloading A Recipe of Parallel Corpora Exploitation for Multilingual Large Language Models\n",
      "Extracting text from arxiv_papers/2407.00436v2.pdf\n",
      "Downloading Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation\n",
      "Extracting text from arxiv_papers/2405.04164v1.pdf\n",
      "Downloading A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4\n",
      "Extracting text from arxiv_papers/2310.12321v1.pdf\n",
      "Extracted text from 100 papers\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "# Directory to save PDFs\n",
    "pdf_dir = \"arxiv_papers\"\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "\n",
    "# Search for papers\n",
    "search = arxiv.Search(\n",
    "    query=\"Large Language Model\",  # You can change the category or keyword\n",
    "    max_results=100,\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "\n",
    "def download_pdf(pdf_url, filename):\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "papers_text = []\n",
    "\n",
    "for result in search.results():\n",
    "    pdf_path = os.path.join(pdf_dir, f\"{result.entry_id.split('/')[-1]}.pdf\")\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Downloading {result.title}\")\n",
    "        download_pdf(result.pdf_url, pdf_path)\n",
    "    else:\n",
    "        print(f\"PDF already downloaded: {pdf_path}\")\n",
    "\n",
    "    print(f\"Extracting text from {pdf_path}\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    papers_text.append({\n",
    "        \"title\": result.title,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "print(f\"Extracted text from {len(papers_text)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3dc3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 documents.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.schema import Document\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(path)\n",
    "            documents.append(Document(page_content=text, metadata={\"source\": filename}))\n",
    "    return documents\n",
    "\n",
    "# Example\n",
    "pdf_folder = \"arxiv_papers\"\n",
    "documents = load_documents_from_folder(pdf_folder)\n",
    "print(f\"Loaded {len(documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3766bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 13882 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"Split into {len(docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69b3e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store saved.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "db = FAISS.from_documents(docs, embedding_model)\n",
    "db.save_local(\"top100_papers_vector_db\")\n",
    "print(\"Vector store saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105de46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "    openai_api_key=\"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\"\n",
    ")\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"top100_papers_vector_db\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "908e1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The title \"Talking About Large Language Models\" and the text do not refer to a person or entity named \"Large Language Models\". Instead, \"Large Language Models\" is a term used to describe a type of artificial intelligence model that processes and generates human-like language.\n",
      "\n",
      "Source documents:\n",
      "2412.10291v1.pdf\n",
      "2402.09748v1.pdf\n",
      "2406.13138v2.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Large Language Models ?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\nSource documents:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(doc.metadata[\"source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05be452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "1 2 3\n",
      "4 5 6\n",
      "7 8 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Matrix:\n",
    "    def __init__(self,rows,cols,elements):\n",
    "        self.rows=rows\n",
    "        self.cols=cols\n",
    "        self.elements=elements\n",
    "    \n",
    "    def print_rows(self):\n",
    "        print(self.rows)\n",
    "        \n",
    "    def print_cols(self):\n",
    "        print(self.cols)\n",
    "        \n",
    "    def print_elements(self):\n",
    "        for i in range(self.rows):\n",
    "            rows=self.elements[i*self.cols:(i+1)*self.cols]\n",
    "            print(' '.join(map(str,rows)))\n",
    "        \n",
    "try:\n",
    "    fl=input().strip()\n",
    "    fl_2,total_elements=fl.split()\n",
    "    rows,cols=map(int,fl_2.lower().split('x'))\n",
    "    total_elements=int(total_elements)\n",
    "    elements=[]\n",
    "    while len(elements) < total_elements:\n",
    "        elements += list(map(int,input().strip().split()))\n",
    "        \n",
    "    matrix=Matrix(rows,cols,elements)\n",
    "    matrix.print_rows()\n",
    "    matrix.print_cols()\n",
    "    matrix.print_elements()\n",
    "\n",
    "except Excepiton:\n",
    "    print('invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f3181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "1 2 3\n",
      "4 5 6\n",
      "7 8 9\n"
     ]
    }
   ],
   "source": [
    "class Matrix:\n",
    "    def __init__(self,rows,cols,elements):\n",
    "        self.rows=rows\n",
    "        self.cols=cols\n",
    "        self.elements=elements\n",
    "        \n",
    "    def print_rows(self):\n",
    "        print(self.rows)\n",
    "        \n",
    "    def print_cols(self):\n",
    "        print(self.cols)\n",
    "        \n",
    "    def print_elements(self):\n",
    "        for i in range(self.rows):\n",
    "            rows=self.elements[i*self.cols:(i+1)*self.cols]\n",
    "            print(' '.join(map(str,rows)))\n",
    "        \n",
    "try:\n",
    "    fl=input().strip()\n",
    "    fl_2,total_elements=fl.split()\n",
    "    rows,cols=map(int,fl_2.lower().split('x'))\n",
    "    total_elements=int(total_elements)\n",
    "    elements=[]\n",
    "    while len(elements) < total_elements:\n",
    "        elements += list(map(int,input().strip().split()))\n",
    "        \n",
    "    matrix=Matrix(rows,cols,elements)\n",
    "    matrix.print_rows()\n",
    "    matrix.print_cols()\n",
    "    matrix.print_elements()\n",
    "\n",
    "except Excepiton:\n",
    "    print('invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78553059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "class Triangle:\n",
    "    def __init__(self, a, b, c):\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "        self.c=c\n",
    "        \n",
    "    def perimeter(self,a,b,c):\n",
    "        return a+b+c\n",
    "        \n",
    "def main():\n",
    "    a=int(input())\n",
    "    b=int(input())\n",
    "    c=int(input())\n",
    "    triangle=Triangle(a,b,c)\n",
    "    \n",
    "    print(triangle.perimeter(a,b,c))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ff6683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Triangle:\n",
    "    def calculate_area(self,base,height):\n",
    "        return base * height // 2\n",
    "\n",
    "base,height=6,6\n",
    "\n",
    "\n",
    "tri=Triangle()\n",
    "tri.calculate_area(base,height)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
